{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Video_Action_Recognition.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7pzOjx3NHtX4d+AfG5pAI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9luZyGG5GVQl"},"source":["# Transfer Learning for Human Activity Recognition from Video with TensorFlow Hub\n","\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"NOnpdmUrH5oh"},"source":["Overview\n","\n","[TensorFlow Hub](https://tfhub.dev/) is a repository of pre-trained TensorFlow models.\n","\n","In this project, I have used pre-trained model from TensorFlow Hub with [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) for Video classification. Transfer learning makes it possible to save training resources and achieve good model generalization even when training on a small dataset. In this project, I will be using [`MoViNet architecture`](https://tfhub.dev/tensorflow/movinet/a5/base/kinetics-600/classification/1)"]},{"cell_type":"markdown","metadata":{"id":"iQrQYQHdweQN"},"source":["Note: Try to run the Notebook in GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hw_7jBXeKxvK","executionInfo":{"status":"ok","timestamp":1622001867302,"user_tz":-330,"elapsed":8670,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}},"outputId":"265d3e0c-167b-4487-9446-8546f58c8e76"},"source":["#!pip install pytube3                                                              # Download pytube to download videos from Youtube\n","!pip install git+https://github.com/ssuwani/pytube\n","from pytube import YouTube\n","\n","!pip install flask-ngrok\n","import flask_ngrok\n","from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import cv2\n","\n","from absl import logging\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(\"Version: \", tf.__version__)\n","print(\"Hub version: \", hub.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/ssuwani/pytube\n","  Cloning https://github.com/ssuwani/pytube to /tmp/pip-req-build-bcz0nrz2\n","  Running command git clone -q https://github.com/ssuwani/pytube /tmp/pip-req-build-bcz0nrz2\n","Requirement already satisfied (use --upgrade to upgrade): pytube==10.8.1 from git+https://github.com/ssuwani/pytube in /usr/local/lib/python3.7/dist-packages\n","Building wheels for collected packages: pytube\n","  Building wheel for pytube (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytube: filename=pytube-10.8.1-cp37-none-any.whl size=46190 sha256=ca89bdedf48f4fcd8f06b4e7527142a9fdf69bde128bf21afc1e92e3a174d25d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-498ivfww/wheels/25/7c/91/be1312a77c2a7ff95e5f9dc1e0ff59113d10b67b4f80d2f4b8\n","Successfully built pytube\n","Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Version:  2.5.0\n","Hub version:  0.12.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OWZWeraWrGWK"},"source":["#Downloading Dataset for Kinetics 600"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"xYDVQvnGVyKv","executionInfo":{"status":"ok","timestamp":1622001876866,"user_tz":-330,"elapsed":2087,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}},"outputId":"1318aeb5-2d20-4956-dc86-8b17c355321a"},"source":["label = pd.read_csv('https://gist.githubusercontent.com/willprice/f19da185c9c5f32847134b87c1960769/raw/9dc94028ecced572f302225c49fcdee2f3d748d8/kinetics_600_labels.csv', index_col='id')\n","train = pd.read_csv('https://raw.githubusercontent.com/rocksyne/kinetics-dataset-downloader/master/dataset_splits/kinetics700/train.csv')\n","test  = pd.read_csv('https://raw.githubusercontent.com/rocksyne/kinetics-dataset-downloader/master/dataset_splits/kinetics600/test.csv')\n","test.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>youtube_id</th>\n","      <th>time_start</th>\n","      <th>time_end</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sipping cup</td>\n","      <td>--0l35AkU34</td>\n","      <td>62</td>\n","      <td>72</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>using inhaler</td>\n","      <td>--71SekUwOA</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>climbing tree</td>\n","      <td>--8YXc8iCt8</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>washing feet</td>\n","      <td>--GkrdYZ9Tc</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>playing kickball</td>\n","      <td>--NFqQGeShc</td>\n","      <td>33</td>\n","      <td>43</td>\n","      <td>test</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              label   youtube_id  time_start  time_end split\n","0       sipping cup  --0l35AkU34          62        72  test\n","1     using inhaler  --71SekUwOA           5        15  test\n","2     climbing tree  --8YXc8iCt8           2        12  test\n","3      washing feet  --GkrdYZ9Tc           0        10  test\n","4  playing kickball  --NFqQGeShc          33        43  test"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"mb215oDTrSQH"},"source":["#Downloading specific video only to avoid storage issues\n","\n","Test the model by changing the input here\n","\n","Choose from train or test dataset\n","\n","Choose the Video"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPAVfsI-e_yw","executionInfo":{"status":"ok","timestamp":1622001886224,"user_tz":-330,"elapsed":3172,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}},"outputId":"8e6f91a2-4ddf-4114-bb8d-f08ce5df5059"},"source":["df = test #@param [\"None\", \"train\", \"test\"] {type:\"raw\", allow-input: true}\n","i = int(input('Enter the index of video between 0 and {}: '.format(len(df))))    "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Enter the index of video between 0 and 56508: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdcCKo0L6yx-","executionInfo":{"status":"ok","timestamp":1622001908164,"user_tz":-330,"elapsed":2751,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}}},"source":["while True:\n","  try: \n","    yt = YouTube('https://www.youtube.com/watch?v='+df.youtube_id[i])\n","    video = yt.streams.first().download()\n","    break\n","  except: \n","    time.sleep(10)\n","    continue"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DK2Q7D6yrlsZ"},"source":["###Get details of video"]},{"cell_type":"code","metadata":{"id":"hvscv0YaeIVH","executionInfo":{"status":"ok","timestamp":1622001916178,"user_tz":-330,"elapsed":497,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}}},"source":["n_frame = cv2.VideoCapture(video).get(cv2.CAP_PROP_FRAME_COUNT)\n","fps = int(cv2.VideoCapture(video).get(cv2.CAP_PROP_FPS))\n","length = yt.length"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ys6yAnJNrtem"},"source":["### Reading and Converting Video to Numpy array"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhZ1d6YE7BFQ","executionInfo":{"status":"ok","timestamp":1622001927728,"user_tz":-330,"elapsed":1928,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}},"outputId":"18f9f97e-743b-43df-b35f-99089a4c1c0e"},"source":["cap = cv2.VideoCapture(video)\n","cv2.VideoCapture.isOpened(cap)\n","frames = []\n","try:\n","  x,y,_ = cap.read()[1].shape\n","  res = min(x,y)\n","except: res = 180\n","while True:\n","  ret, frame = cap.read()\n","  if not ret:\n","    break\n","   \n","  frame = cv2.resize(frame, (res,res))\n","  frame = frame[:, :, [2, 1, 0]]\n","  frames.append(frame)\n","   \n","  if len(frames) == 0:\n","    break\n","\n","cap.release()\n","frames = frames[df.time_start[i]*fps:df.time_end[i]*fps]\n","array = np.array(frames) / 255.0\n","array = array.reshape(1,df.time_end[i]*fps-df.time_start[i]*fps,res,res,3)\n","array.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 300, 360, 360, 3)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"CJk21O2pr15l"},"source":["#Importing MoViNet A-5 from TensorFlow Hub"]},{"cell_type":"markdown","metadata":{"id":"MHG5TDQEzL6B"},"source":["####[Theory](https://www.arxiv-vanity.com/papers/2103.11511/)\n","\n","Mobile Video Networks (MoViNets), a family of computation and memory efficient video networks that can operate on streaming video for online inference. 3D convolutional neural networks (CNNs) are accurate at video recognition but require large computation and memory budgets and do not support online inference, making them difficult to work on"]},{"cell_type":"markdown","metadata":{"id":"mgovBVOE02-M"},"source":["It works in Three steps:\n","\n","\n",">First define a MoViNet search space to allow Neural Architecture Search (NAS) to efficiently trade-off spatiotemporal feature representations.\n","\n","\n",">Then introduce Stream Buffers for MoViNets, which process videos in small consecutive subclips, requiring constant memory without sacrificing long temporal dependencies, and which enable online inference.\n","\n","\n","\n",">Finally, create Temporal Ensembles of streaming MoViNets, regaining the slightly lost accuracy from the stream buffer.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PkVHNnQtsK0s"},"source":["#Building the Model"]},{"cell_type":"code","metadata":{"id":"SZgOKnRmV1H1","executionInfo":{"status":"ok","timestamp":1622002040154,"user_tz":-330,"elapsed":99193,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}}},"source":["logging.set_verbosity(logging.ERROR)\n","\n","inputs = tf.keras.layers.Input( shape=[None, None, None, 3], dtype=tf.float32)\n","\n","encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/movinet/a5/base/kinetics-600/classification/1\")\n","\n","# Important: due to a bug in the tf.nn.conv3d CPU implementation, we must\n","# compile with tf.function to enforce correct behavior. Otherwise, the output\n","# on CPU may be incorrect.\n","encoder.call = tf.function(encoder.call, experimental_compile=True)\n","\n","outputs = encoder(dict(image=inputs))\n","\n","model = tf.keras.Model(inputs, outputs)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7iTbOSMsFoc"},"source":["# Check Output"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIpOGDree0Ce","executionInfo":{"status":"ok","timestamp":1622002143007,"user_tz":-330,"elapsed":102895,"user":{"displayName":"Shalin Patel","photoUrl":"","userId":"01920459027758915353"}},"outputId":"db0a8bb8-b107-4025-f292-c88dcb7db8bd"},"source":["#example_input = tf.ones([1, 8, 320, 320, 3])\n","example_output = model(array)\n","print('Predicted: ', label.name[np.argmax(example_output[0])])\n","print('Actual:    ', df.label[i])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Predicted:  using inhaler\n","Actual:     using inhaler\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jll9cHhosYLo"},"source":[""],"execution_count":null,"outputs":[]}]}